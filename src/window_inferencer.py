# src/window_inferencer

import os
import json
import pandas as pd
import numpy as np
import mlflow
import tensorflow as tf
import matplotlib.pyplot as plt

from .config import config
from .self_attention_block import SelfAttentionBlock
from .model_trainer import CategoricalFocalLoss, MacroF1Score

from typing import Tuple, cast, Dict, Any
from tensorflow.keras.models import Model, load_model

class WindowInference:
    """
    Ð¦ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ Ð´Ð»Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ ÐºÐ°ÑÐºÐ°Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ°.
    Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð²ÑÐµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ Ð¿Ñ€Ð¸ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸,
    ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð² config.yaml (load_from_mlflow).
    """
    def __init__(self, prefix='top'):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ°.

        Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð²ÑÐµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹:
        - ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ stage1 Ð¸ stage2.
        - Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¾Ð±ÐµÐ¸Ñ… ÑÑ‚Ð°Ð´Ð¸Ð¹.
        - Ð”ÐµÑ‚Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ ÑÐ²Ð¾Ð´ÐºÑƒ Ð¿Ð¾ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°Ð¼ Ð¸Ð· JSON-Ñ„Ð°Ð¹Ð»Ð°.
        - Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¸ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð² GUI.

        :param prefix: ÐŸÑ€ÐµÑ„Ð¸ÐºÑ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° ('top', 'cross' Ð¸ Ñ‚.Ð´.), Ð´Ð»Ñ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð±ÑƒÐ´ÑƒÑ‚ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ.
        """
        print("Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ WindowInference...")
        self.prefix = prefix
        self.config = config
        
        print("\n" + "="*50)
        print("Ð—ÐÐŸÐ£Ð¡Ðš Ð¢Ð•Ð¡Ð¢Ð˜Ð ÐžÐ’ÐÐÐ˜Ð¯ ÐÐžÐ’ÐžÐ“Ðž ÐšÐÐ¡ÐšÐÐ”ÐÐžÐ“Ðž Ð˜ÐÐ¤Ð•Ð Ð•ÐÐ¡Ð")
        print("="*50)

        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        self.model_stage1 = self._load_model_for_stage('stage1')
        self.model_stage2 = self._load_model_for_stage('stage2')
        print("ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ stage1 Ð¸ stage2 ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹.")

###        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ
###        self.data_stage1 = self._load_data_for_stage('stage1')
###        self.data_stage2 = self._load_data_for_stage('stage2')
###        print("Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð¸ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ stage1 Ð¸ stage2 ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹.")
###
###        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ‡ÐµÐ½Ð½Ñ‹Ð¹ Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…
###        self.metadata_labeled_s1 = self.data_stage1['metadata_labeled']
###        self.metadata_labeled_s2 = self.data_stage2['metadata_labeled']
###        
###        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ñ‹Ð¹ Ð¸Ð½Ð´ÐµÐºÑ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð¿Ð¸ÐºÐ° (train/val/test)
###        self.split_status_index = { (meta[0], meta[1]): meta[2] for meta in self.metadata_labeled_s1 }
###
###        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¸Ð½Ð´ÐµÐºÑÑ‹ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°
###        self.metadata_index_s1 = self._create_metadata_index(self.data_stage1['metadata_test'])
###        self.metadata_index_s2 = self._create_metadata_index(self.data_stage2['metadata_test'])
###        print("Ð˜Ð½Ð´ÐµÐºÑÑ‹ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹.")

        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡
        # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð¢Ð•Ð¡Ð¢ÐžÐ’Ð«Ð• Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ "Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€"
        self.data_stage1_test_only = self._load_test_data_for_stage('stage1')
        print("Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ° Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹.")

        # Ð’Ð¡Ð• Ð´Ð°Ð½Ð½Ñ‹Ðµ (train+val+test) Ð´Ð»Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ "ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð¾ ID"
        self.data_stage1_full = self._load_data_for_stage('stage1')
        self.data_stage2_full = self._load_data_for_stage('stage2')
        print("ÐŸÐ¾Ð»Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ° Ð¿Ð¾ ID Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹.")

        # --- Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¸Ð½Ð´ÐµÐºÑÑ‹ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° ---
        # Ð˜Ð½Ð´ÐµÐºÑ Ð¿Ð¾ Ð’Ð¡Ð•Ðœ Ð´Ð°Ð½Ð½Ñ‹Ð¼ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾ ID
        self.metadata_index_s1 = self._create_metadata_index(self.data_stage1_full['metadata'])
        self.metadata_index_s2 = self._create_metadata_index(self.data_stage2_full['metadata'])
        print("Ð˜Ð½Ð´ÐµÐºÑÑ‹ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾ Ð²ÑÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹.")
        
        # --- Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ ---
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ‡ÐµÐ½Ð½Ñ‹Ð¹ Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ GUI
        self.metadata_labeled_s1 = self.data_stage1_full['metadata_labeled']

        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼ÐµÑ‚ÐºÐ¸ ÐºÐ»Ð°ÑÑÐ¾Ð²
        self.class_labels_s1 = self.config['class_labels']['stage1']
        self.class_labels_s2 = self.config['class_labels']['stage2']
        self.display_names = self.config['display_names']

        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´ÐµÑ‚Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ ÑÐ²Ð¾Ð´ÐºÑƒ Ð¿Ð¾ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°Ð¼ Ð´Ð»Ñ "ÑƒÐ¼Ð½Ð¾Ð³Ð¾" dropdown Ð¸ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸
        self.patient_summary = self._load_patient_summary()
        self.formatted_patient_list = self._create_formatted_patient_list()

        print("InferencePipeline Ð³Ð¾Ñ‚Ð¾Ð² Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ðµ.")

    def _load_model_for_stage(self, stage: str) -> Model:
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð¹ ÑÑ‚Ð°Ð´Ð¸Ð¸, ÑÐ¾Ð±Ð»ÑŽÐ´Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÑƒ `load_from_mlflow` Ð¸Ð· config.yaml."""
        load_from_mlflow = self.config['execution']['load_from_mlflow']
        # ÐžÐ±ÑŠÐµÐºÑ‚Ñ‹, Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð»ÑŽÐ±Ð¾Ð¹ Ð¸Ð· Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
        custom_objects = {
            'SelfAttentionBlock': SelfAttentionBlock,
            'CategoricalFocalLoss': CategoricalFocalLoss,
            'MacroF1Score': MacroF1Score                            ## Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐºÐ»Ð°ÑÑ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð²Ð¼ÐµÑÑ‚Ð¾ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸
            # 'f1_score': f1_score
        }
        model = None

        # Ð¡Ð¦Ð•ÐÐÐ Ð˜Ð™ 1: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸Ð· MLflow
        if load_from_mlflow:
            run_id = self.config['execution']['mlflow_run_id'].get(stage)
            if not run_id:
                raise ValueError(f"load_from_mlflow=True, Ð½Ð¾ mlflow_run_id Ð´Ð»Ñ ÑÑ‚Ð°Ð´Ð¸Ð¸ '{stage}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² config.yaml")
            
            print(f"Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÑÑ‚Ð°Ð´Ð¸Ð¸ '{stage}' Ð¸Ð· MLflow run_id: {run_id}")
            try:
                model_uri = f"runs:/{run_id}/model"
                model = mlflow.keras.load_model(model_uri, custom_objects=custom_objects)
                print(f"ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÑÑ‚Ð°Ð´Ð¸Ð¸ '{stage}' Ð¸Ð· MLflow ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°.")
            except Exception as e:
                raise RuntimeError(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸Ð· MLflow Ð´Ð»Ñ run_id {run_id}. ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")
        # Ð¡Ð¦Ð•ÐÐÐ Ð˜Ð™ 2: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ Ð´Ð¸ÑÐºÐ°
        else:
            model_path = os.path.join(
                self.config['paths']['model_dir'],
                f"{self.prefix}_{stage}_{self.config['paths']['best_model']}"
            )
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð¿Ð¾ Ð¿ÑƒÑ‚Ð¸: {model_path}. Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð° Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð°.")
            
            print(f"Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÑÑ‚Ð°Ð´Ð¸Ð¸ '{stage}' Ñ Ð´Ð¸ÑÐºÐ°: {model_path}")
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ tf.keras.models.load_model Ð´Ð»Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²
            model = tf.keras.models.load_model(model_path, custom_objects=custom_objects, compile=False)
            print(f"ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÑÑ‚Ð°Ð´Ð¸Ð¸ '{stage}' Ñ Ð´Ð¸ÑÐºÐ° ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°.")

        if model is None:
            raise RuntimeError(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÑÑ‚Ð°Ð´Ð¸Ð¸ '{stage}' Ð½Ð¸ Ð¾Ð´Ð½Ð¸Ð¼ Ð¸Ð· ÑÐ¿Ð¾ÑÐ¾Ð±Ð¾Ð².")

        return cast(Model, model)

    def _load_data_for_stage(self, stage: str) -> Dict[str, np.ndarray]:
        """Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð’Ð¡Ð•Ð¥ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð¹ ÑÑ‚Ð°Ð´Ð¸Ð¸."""
        dataset_path = os.path.join(
            self.config['paths']['data_dir'],
            f"{self.prefix}_{stage}_{self.config['data']['dataset_name']}"
        )
        if not os.path.exists(dataset_path):
            raise FileNotFoundError(f"Ð¤Ð°Ð¹Ð» Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {dataset_path}.")
            
        with np.load(dataset_path, allow_pickle=True) as data:
            # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð²ÑÐµ Ñ‡Ð°ÑÑ‚Ð¸ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°
            X = np.concatenate([data['X_train'], data['X_val'], data['X_test']], axis=0)
            y = np.concatenate([data['y_train'], data['y_val'], data['y_test']], axis=0)
            metadata = np.concatenate([data['metadata_train'], data['metadata_val'], data['metadata_test']], axis=0)
            
            return {
                'X': X,
                'y': y,
                'metadata': metadata,
                'metadata_labeled': data['metadata_labeled']
            }
        
    def _load_test_data_for_stage(self, stage: str) -> Dict[str, np.ndarray]:
        """Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¢Ð•Ð¡Ð¢ÐžÐ’Ð«Ð¥ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð¹ ÑÑ‚Ð°Ð´Ð¸Ð¸."""
        dataset_path = os.path.join(
            self.config['paths']['data_dir'],
            f"{self.prefix}_{stage}_{self.config['data']['dataset_name']}"
        )
        if not os.path.exists(dataset_path):
            raise FileNotFoundError(f"Ð¤Ð°Ð¹Ð» Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {dataset_path}.")
            
        with np.load(dataset_path, allow_pickle=True) as data:
            return {
                'X_test': data['X_test'],
                'y_test': data['y_test'],
                'metadata_test': data['metadata_test'],
            }
           
    def _create_metadata_index(self, metadata_array: np.ndarray) -> Dict[Tuple, int]:
        """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¸Ð½Ð´ÐµÐºÑÐ° Ð² Ð¼Ð°ÑÑÐ¸Ð²Ðµ Ð¿Ð¾ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼."""
        return {tuple(meta): i for i, meta in enumerate(metadata_array)}

    def predict_random(self) -> Dict[str, Any]:
        """
        Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÑ‚ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ R-Ð¿Ð¸Ðº Ð¸Ð· Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸ stage1, Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚
        Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÐºÐ°ÑÐºÐ°Ð´Ð½Ñ‹Ð¹ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½Ñ Ð¸ ÐÐ• Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (ÑÑ‚Ð¾ Ð·Ð°Ð´Ð°Ñ‡Ð° GUI).
        """
        print("\nÐ—Ð°Ð¿ÑƒÑÐº Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ° Ð´Ð»Ñ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ð¾Ð³Ð¾ R-Ð¿Ð¸ÐºÐ°.")
        
        # 1. Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ Ð¸Ð½Ð´ÐµÐºÑ Ð¸Ð· Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸ stage1
        num_test_samples = len(self.data_stage1_test_only['X_test'])        
        random_index = np.random.randint(0, num_test_samples)
        
        # 2. ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ "Ð¿Ð°ÑÐ¿Ð¾Ñ€Ñ‚" ÑÑ‚Ð¾Ð³Ð¾ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ð¾Ð³Ð¾ Ð¿Ð¸ÐºÐ°
        metadata_to_find = tuple(self.data_stage1_test_only['metadata_test'][random_index])
        patient_id, sample_id = metadata_to_find
        
        print(f"Ð’Ñ‹Ð±Ñ€Ð°Ð½ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ R-Ð¿Ð¸Ðº: Patient ID = {patient_id}, Sample ID = {int(sample_id)}")
        
        # 3. Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¼ÐµÑ‚Ð¾Ð´, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð²ÐµÑ€Ð½ÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸
        results = self.predict_by_id(patient_id, int(sample_id))

        # ÐŸÐµÑ‡Ð°Ñ‚Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ Ð´Ð»Ñ Ð»Ð¾Ð³Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        print("\nÐ ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÐºÐ°ÑÐºÐ°Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ°:")
        true_label_s1_display = self.display_names.get(results['true_label_s1'], results['true_label_s1'])
        pred_label_s1_display = self.display_names.get(results['prediction_s1'], results['prediction_s1'])
        print(f"Ð˜ÑÑ‚Ð¸Ð½Ð½Ð°Ñ Ð¼ÐµÑ‚ÐºÐ° Stage 1: {true_label_s1_display}")
        print(f"ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Stage 1: {pred_label_s1_display} (Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {results['confidence_s1']:.2f}%)")
        ### print(f"Ð˜ÑÑ‚Ð¸Ð½Ð½Ð°Ñ Ð¼ÐµÑ‚ÐºÐ° Stage 1: {results['true_label_s1']}")
        ### print(f"ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Stage 1: {results['prediction_s1']} (Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {results['confidence_s1']:.2f}%)")
        
        title = f"ÐŸÐ°Ñ†Ð¸ÐµÐ½Ñ‚: {results['patient_id']}, Ð¡ÑÐ¼Ð¿Ð»: {results['sample_id']}\n"
        title += f"ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ S1: {results['prediction_s1']}"

        if 'prediction_s2' in results:
            true_label_s2_display = self.display_names.get(results['true_label_s2'], results['true_label_s2'])
            pred_label_s2_display = self.display_names.get(results['prediction_s2'], results['prediction_s2'])
            print(f"Ð˜ÑÑ‚Ð¸Ð½Ð½Ð°Ñ Ð¼ÐµÑ‚ÐºÐ° Stage 2: {true_label_s2_display}")
            print(f"ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Stage 2: {pred_label_s2_display} (Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {results['confidence_s2']:.2f}%)")
            ### print(f"Ð˜ÑÑ‚Ð¸Ð½Ð½Ð°Ñ Ð¼ÐµÑ‚ÐºÐ° Stage 2: {results['true_label_s2']}")
            ### print(f"ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Stage 2: {results['prediction_s2']} (Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {results['confidence_s2']:.2f}%)")
            ### title += f" -> S2: {results['prediction_s2']}"

            common_result = results['confidence_s1'] * results['confidence_s2'] / 100
            print(f"ÐžÐ±Ñ‰Ð°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {common_result:.2f}%")
            ### print(f"Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ 2 ÑÑ‚Ð°Ð´Ð¸ÑÐ¼: {common_result:.2f}%)")
        else:
            print("Ð˜Ð½Ñ„ÐµÑ€ÐµÐ½Ñ Stage 2 Ð½Ðµ Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ð»ÑÑ.")

        # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ, Ð¿ÐµÑ€ÐµÐ´Ð°Ð²Ð°Ñ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ÐºÐ½Ð° Ð¸ ÑÑ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
        ### self.visualize_peak(results['window_data'], title=title)
            
        return results

    def predict_by_id(self, patient_id: str, sample_id: int) -> Dict[str, Any]:
        """
        Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÐºÐ°ÑÐºÐ°Ð´Ð½Ñ‹Ð¹ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½Ñ Ð´Ð»Ñ R-Ð¿Ð¸ÐºÐ° Ð¿Ð¾ ÐµÐ³Ð¾ "Ð¿Ð°ÑÐ¿Ð¾Ñ€Ñ‚Ñƒ" (ID).
        
        :param patient_id: ID Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð° (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, '101').
        :param sample_id: ID ÑÑÐ¼Ð¿Ð»Ð° (Ð¾Ñ‚ÑÑ‡ÐµÑ‚Ð°), Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¼ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ R-Ð¿Ð¸Ðº.
        :return: Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ð¼Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ°.
        """
        peak_id = (str(patient_id), sample_id) # Ð“Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð²Ñ‹Ð¹ Ñ‚Ð¸Ð¿ ID Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°
        results = {'patient_id': patient_id, 'sample_id': sample_id}

        #################################################################################
        # Ð­Ñ‚Ð°Ð¿ 1: ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Stage 1
        #################################################################################
        if peak_id not in self.metadata_index_s1:
            raise ValueError(f"R-Ð¿Ð¸Ðº Ñ ID {peak_id} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ… stage1.")
                    
        idx_s1 = self.metadata_index_s1[peak_id]
        window_s1 = self.data_stage1_full['X'][idx_s1]
        true_label_ohe_s1 = self.data_stage1_full['y'][idx_s1]
        true_label_idx_s1 = int(true_label_ohe_s1) # Ð”Ð»Ñ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¾Ð³Ð¾ ÑÐ»ÑƒÑ‡Ð°Ñ

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ batch-Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
        prediction_s1_raw = self.model_stage1.predict(np.expand_dims(window_s1, axis=0))[0]
        
        pred_label_idx_s1 = int(prediction_s1_raw[0] > 0.5)
        # Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð² Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð¼ ÐºÐ»Ð°ÑÑÐµ
        if pred_label_idx_s1 == 1: # Ð•ÑÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½ 'Alert'
            confidence_s1 = prediction_s1_raw[0] * 100
        else: # Ð•ÑÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½ 'Good'
            confidence_s1 = (1 - prediction_s1_raw[0]) * 100

        results.update({
            'window_data': window_s1,
            'true_label_s1': self.class_labels_s1[true_label_idx_s1],
            'prediction_s1': self.class_labels_s1[pred_label_idx_s1],
            'confidence_s1': confidence_s1
        })
        
        #################################################################################
        # Ð­Ñ‚Ð°Ð¿ 2: Ð£ÑÐ»Ð¾Ð²Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Stage 2
        #################################################################################
        # ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ stage1 Ð±Ñ‹Ð»Ð¾ "Alert"
        if pred_label_idx_s1 == 1:
            if peak_id not in self.metadata_index_s2:
                print(f"ÐŸÑ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ: ÐŸÐ¸Ðº {peak_id} Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½ ÐºÐ°Ðº 'Alert', Ð½Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ… stage2.")
                return results

            idx_s2 = self.metadata_index_s2[peak_id]
            # Ð’Ð°Ð¶Ð½Ð¾: Ð´Ð»Ñ stage2 Ð¼Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° stage2, Ð½Ð¾ Ð¼Ð¾Ð¶ÐµÐ¼ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾ÐºÐ½Ð¾ Ð¸Ð· stage1
            window_s2 = self.data_stage2_full['X'][idx_s2]
            true_label_ohe_s2 = self.data_stage2_full['y'][idx_s2]
            true_label_idx_s2 = np.argmax(true_label_ohe_s2)

            prediction_s2_raw = self.model_stage2.predict(np.expand_dims(window_s2, axis=0))[0]
            pred_label_idx_s2 = np.argmax(prediction_s2_raw)
            
            results.update({
                'true_label_s2': self.class_labels_s2[true_label_idx_s2],
                'prediction_s2': self.class_labels_s2[pred_label_idx_s2],
                'confidence_s2': np.max(prediction_s2_raw) * 100,
                'full_prediction_s2': prediction_s2_raw # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²ÐµÑÑŒ Ð²ÐµÐºÑ‚Ð¾Ñ€ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÐµÐ¹
            })
            
        return results
    
    def visualize_peak(self, window_data: np.ndarray, title: str = "Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ R-Ð¿Ð¸ÐºÐ°"):
        """
        Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ Ð¸ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°ÐµÑ‚ Ð³Ñ€Ð°Ñ„Ð¸Ðº Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¾ÐºÐ½Ð° ÑÐ¸Ð³Ð½Ð°Ð»Ð°.
        
        :param window_data: ÐžÐ´Ð½Ð¾Ð¼ÐµÑ€Ð½Ñ‹Ð¹ numpy-Ð¼Ð°ÑÑÐ¸Ð² Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¾ÐºÐ½Ð°.
        :param title: Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð´Ð»Ñ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ°.
        """
        plt.figure(figsize=(12, 4))
        plt.plot(window_data)
        plt.title(title)
        plt.xlabel("ÐžÑ‚ÑÑ‡ÐµÑ‚Ñ‹ (samples)")
        plt.ylabel("ÐÐ¼Ð¿Ð»Ð¸Ñ‚ÑƒÐ´Ð°")
        plt.grid(True)
        plt.show()

    def get_patient_list(self) -> list:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ñ‚ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº ÑƒÐ¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ID Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð¾Ð²."""
        patient_ids = {meta[0] for meta in self.metadata_labeled_s1}
        return sorted(list(patient_ids))

    def get_peaks_for_patient(self, patient_id: str) -> list:
        """
        Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÐŸÐžÐ›ÐÐ«Ð™, Ð¾Ñ‚ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº R-Ð¿Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°,
        Ñ€Ð°Ð·Ð¼ÐµÑ‡ÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾ Ð¿Ñ€Ð¸Ð½Ð°Ð´Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸ Ðº Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐµ (train/val/test).
        """
        if not patient_id:
            return []
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… ÑÑÐ¼Ð¿Ð»Ð¾Ð² Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð¹ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸
        test_samples = {meta[1] for meta in self.data_stage1_test_only['metadata_test'] if str(meta[0]) == str(patient_id)} ## Ð”ÐžÐ‘ÐÐ’Ð›Ð•ÐÐ

        patient_peaks_text = []
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ self.metadata_labeled_s1, Ñ‚Ð°Ðº ÐºÐ°Ðº Ð² Ð½ÐµÐ¼ ÐµÑÑ‚ÑŒ Ð²ÑÐµ Ð¿Ð¸ÐºÐ¸
        for p_id, s_id, split_label in self.metadata_labeled_s1:
            if str(p_id) == str(patient_id):
                # ÐÐ°ÑˆÐ»Ð¸ Ð¿Ð¸Ðº Ð½ÑƒÐ¶Ð½Ð¾Ð³Ð¾ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°. Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ‚Ñ€Ð¾ÐºÑƒ.
                # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: "Sample_ID [SPLIT_LABEL]"
                label_text = f"{s_id} [{split_label.upper()}]"

                # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¿Ð¾Ð¼ÐµÑ‚ÐºÑƒ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð¿Ð¸ÐºÐ¾Ð²
                if s_id in test_samples:
                    label_text += " ðŸ§ª"

                patient_peaks_text.append(label_text)
        return patient_peaks_text
    
    def _load_patient_summary(self) -> dict:
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ JSON-Ñ„Ð°Ð¹Ð» Ñ Ð´ÐµÑ‚Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¾Ð¹ Ð¿Ð¾ Ð¿Ð¸ÐºÐ°Ð¼ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð¾Ð²."""
        summary_path = os.path.join(self.config['paths']['data_dir'], "patient_detailed_summary.json")
        if not os.path.exists(summary_path):
            print(f"ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: Ð¤Ð°Ð¹Ð» ÑÐ²Ð¾Ð´ÐºÐ¸ {summary_path} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½. 'Ð£Ð¼Ð½Ñ‹Ð¹' ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð¾Ð² Ð±ÑƒÐ´ÐµÑ‚ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½.")
            return {}
        try:
            with open(summary_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"ÐžÐ¨Ð˜Ð‘ÐšÐ Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¸Ð»Ð¸ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ðµ JSON-ÑÐ²Ð¾Ð´ÐºÐ¸: {e}")
            return {}

    def _create_formatted_patient_list(self) -> list:
        """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð¾Ð² Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ 'ID 101 [N+(98.7%), N-(0.5%)]' Ð´Ð»Ñ Dropdown."""
        if not self.patient_summary:
            return self.get_patient_list() # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº, ÐµÑÐ»Ð¸ ÑÐ²Ð¾Ð´ÐºÐ° Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ð»Ð°ÑÑŒ

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ "Ð±ÐµÐ»Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº" Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð¾Ð², Ñƒ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ñ‚Ð¾Ñ‡Ð½Ð¾ ÐµÑÑ‚ÑŒ ÐºÐ°Ð½Ð°Ð» MLII,
        # Ð¸Ð· ÑƒÐ¶Ðµ Ð¾Ñ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ….
        pids_with_mlii = {str(meta[0]) for meta in self.data_stage1_full['metadata']}

        formatted_list = []
        # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ ID Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð° (ÐºÐ»ÑŽÑ‡Ð¸ ÑÐ»Ð¾Ð²Ð°Ñ€Ñ)
        sorted_patient_ids = sorted(self.patient_summary.keys(), key=lambda x: int(x))

        for pid in sorted_patient_ids:
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚ Ð² Ð½Ð°ÑˆÐµÐ¼ "Ð±ÐµÐ»Ð¾Ð¼ ÑÐ¿Ð¸ÑÐºÐµ".
            if pid not in pids_with_mlii:
                continue # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ - Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¸ Ð½Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº.
            
            data = self.patient_summary[pid]
            distribution = data.get("distribution", {})
            
            # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ»Ð°ÑÑÑ‹ Ð¿Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ñƒ (Ð¾Ñ‚ Ð±Ð¾Ð»ÑŒÑˆÐµÐ³Ð¾ Ðº Ð¼ÐµÐ½ÑŒÑˆÐµÐ¼Ñƒ)
            sorted_classes = sorted(distribution.items(), key=lambda item: item[1]['total_percent'], reverse=True)
            
            stats = []
            for class_name, class_data in sorted_classes:
                percent = class_data['total_percent']

                # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ ÑÐ¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Dropdown
                short_name = class_name
                if class_name == 'N+N':
                    short_name = 'N+'
                elif class_name == 'N (Ð¿Ð¾ Aux Ð½Ðµ N)':
                    short_name = 'N-'
                    
                stats.append(f"{short_name}({percent:.2f}%)")
                
            stats_str = ", ".join(stats)
            formatted_list.append(f"ID {pid} [{stats_str}]")
        
        return formatted_list
        
    def get_patient_stats_markdown(self, formatted_patient_str: str) -> str:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ markdown-Ð¾Ñ‚Ñ‡ÐµÑ‚ Ð¿Ð¾ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ñƒ Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð² GUI."""
        if not formatted_patient_str or not self.patient_summary:
            return "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°, Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑƒÐ²Ð¸Ð´ÐµÑ‚ÑŒ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½ÑƒÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ."

        try:
            pid = formatted_patient_str.split(' ')[1]
        except IndexError:
            return "ÐžÑˆÐ¸Ð±ÐºÐ°: Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ ID Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°."
        
        data = self.patient_summary.get(pid)
        if not data:
            return f"Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð´Ð»Ñ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð° {pid} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°."

        total_peaks = data['total_peaks']
        distribution = data.get("distribution", {})
        
        report = [f"### Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ñƒ {pid}", f"**Ð’ÑÐµÐ³Ð¾ R-Ð¿Ð¸ÐºÐ¾Ð²:** {total_peaks}\n"]

        # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð»Ñ ÐºÑ€Ð°ÑÐ¸Ð²Ð¾Ð³Ð¾ Ð²Ñ‹Ð²Ð¾Ð´Ð°
        sorted_classes = sorted(distribution.items(), key=lambda item: item[1]['total_percent'], reverse=True)

        for class_name, class_data in sorted_classes:
            display_name = self.display_names.get(class_name, class_name)
            report.append(f"- **{display_name}:** {class_data['total_percent']:.2f}%")
            ### report.append(f"- **{class_name}:** {class_data['total_percent']}%")
            details = class_data.get('details', {})
            if len(details) > 1: # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð´ÐµÑ‚Ð°Ð»Ð¸, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð² Ð³Ñ€ÑƒÐ¿Ð¿Ðµ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚Ð¸Ð¿Ð°
                detail_parts = []
                for raw_type, percent in details.items():
                    detail_parts.append(f"{raw_type} ({percent}%)")
                report.append(f"  - `{' / '.join(detail_parts)}`")
        
        return "\n".join(report)
    
    def get_ecg_region_data(self, patient_id: str, center_percent: float) -> dict | None:
        """
        Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ÑƒÑ‡Ð°ÑÑ‚Ð¾Ðº Ð­ÐšÐ“-ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ R-Ð¿Ð¸ÐºÐ°Ñ… Ð´Ð»Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸.

        :param patient_id: ID Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°.
        :param center_percent: ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚ Ð¾Ñ‚ Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð¿Ð¸ÑÐ¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð±ÑƒÐ´ÐµÑ‚ Ñ†ÐµÐ½Ñ‚Ñ€Ð¾Ð¼ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ (0-100).
        :return: Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð´Ð»Ñ Ð¾Ñ‚Ñ€Ð¸ÑÐ¾Ð²ÐºÐ¸ Ð¸Ð»Ð¸ None Ð² ÑÐ»ÑƒÑ‡Ð°Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸.
        """
        # 1. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÑ‹Ñ€Ð¾Ð³Ð¾ ÑÐ¸Ð³Ð½Ð°Ð»Ð°
        signal_path = os.path.join(self.config['paths']['temp_dir'], f"{patient_id}.csv")
        if not os.path.exists(signal_path):
            print(f"ÐžÐ¨Ð˜Ð‘ÐšÐ: Ð¤Ð°Ð¹Ð» ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {signal_path}")
            return None
        
        try:
            df_signal = pd.read_csv(signal_path)
            # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð¸Ð¼ÐµÐ½Ð° ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð¾Ñ‚ ÐºÐ°Ð²Ñ‹Ñ‡ÐµÐº Ð¸ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ð¾Ð²
            df_signal.columns = [col.strip().strip("'") for col in df_signal.columns]
            df_signal.rename(columns={"sample #": "Sample"}, inplace=True)

            target_channel = self.config['data']['target_channel_name']
            df_signal = df_signal[['Sample', target_channel]].rename(columns={target_channel: 'Signal'})

            ### # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½ÑƒÐ¶Ð½Ñ‹Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸
            ### df_signal = pd.read_csv(signal_path, usecols=["'sample #'", f"'{self.config['data']['target_channel_name']}'"])
            ### df_signal.columns = ['Sample', 'Signal']
        except Exception as e:
            print(f"ÐžÐ¨Ð˜Ð‘ÐšÐ Ð¿Ñ€Ð¸ Ñ‡Ñ‚ÐµÐ½Ð¸Ð¸ CSV Ñ„Ð°Ð¹Ð»Ð° {signal_path}: {e}")
            return None

        total_samples = df_signal['Sample'].max()
        
        # 2. ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð³Ñ€Ð°Ð½Ð¸Ñ† Ð±ÑƒÑ„ÐµÑ€Ð°
        buffer_percent = config['data']['visualization']['buffer_percent']
        center_sample = int(total_samples * (center_percent / 100))

        start_sample = max(0, int(center_sample - (total_samples * buffer_percent / 100)))
        end_sample = min(total_samples, int(center_sample + (total_samples * buffer_percent / 100)))

        # Ð’Ñ‹Ñ€ÐµÐ·Ð°ÐµÐ¼ ÐºÑƒÑÐ¾Ðº ÑÐ¸Ð³Ð½Ð°Ð»Ð°
        region_signal_df = df_signal[(df_signal['Sample'] >= start_sample) & (df_signal['Sample'] <= end_sample)]
        
        # 3. Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ R-Ð¿Ð¸ÐºÐ¾Ð²
        # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²ÑÐµ Ð¿Ð¸ÐºÐ¸ Ð´Ð»Ñ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°
        all_patient_peaks_info = [
            (p_id, s_id, split) for p_id, s_id, split in self.metadata_labeled_s1 if str(p_id) == str(patient_id)
        ]

        # Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ð¸Ñ… Ð¿Ð¾ Ð½Ð°ÑˆÐµÐ¼Ñƒ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ñƒ
        region_peaks_info = [
            peak for peak in all_patient_peaks_info if start_sample <= peak[1] <= end_sample
        ]

        # ÐžÐ±Ð¾Ð³Ð°Ñ‰Ð°ÐµÐ¼ Ð¿Ð¸ÐºÐ¸ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¼ Ñ‚Ð¸Ð¿Ð¾Ð¼ (N, V, A...) Ð¸Ð· Ð¿ÐµÑ€Ð²Ð¾Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ñƒ Ð½Ð°Ñ ÑƒÐ¶Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½!
        # Ð­Ñ‚Ð¾ ÑÐ°Ð¼Ñ‹Ð¹ Ð½Ð°Ð´ÐµÐ¶Ð½Ñ‹Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð±.
        region_peaks = []
        for p_id, s_id, split in region_peaks_info:
            peak_type = '?' # Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ

            # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¸Ñ‰ÐµÐ¼ Ð² Ð¸Ð½Ð´ÐµÐºÑÐµ stage2 (Ð´Ð»Ñ Ð²ÑÐµÑ… Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹ Ð¸ N-)
            idx2 = self.metadata_index_s2.get((p_id, s_id))
            if idx2 is not None:
                y_ohe = self.data_stage2_full['y'][idx2]
                peak_type = self.class_labels_s2[np.argmax(y_ohe)]
            else:
                # Ð•ÑÐ»Ð¸ Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¸, Ð¸Ñ‰ÐµÐ¼ Ð² Ð¸Ð½Ð´ÐµÐºÑÐµ stage1 (ÑÑ‚Ð¾ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ N+N)
                idx1 = self.metadata_index_s1.get((p_id, s_id))
                if idx1 is not None:
                    # Ð£ stage1 Ð±Ð¸Ð½Ð°Ñ€Ð½Ð°Ñ Ð¼ÐµÑ‚ÐºÐ°, 0 - ÑÑ‚Ð¾ 'Good (N+N)'
                    if int(self.data_stage1_full['y'][idx1]) == 0:
                        peak_type = 'N+N'

            region_peaks.append({
                'sample': s_id,
                'type': peak_type,
                'split': split
            })

        return {
            "signal_df": region_signal_df,
            "peaks": region_peaks,
            "total_samples": total_samples
        }